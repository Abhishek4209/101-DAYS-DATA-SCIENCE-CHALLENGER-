{"cells":[{"cell_type":"markdown","metadata":{"id":"RrvS_JzwsrNk"},"source":["### Introduction\n","\n",">AlexNet was designed by Hinton, winner of the 2012 ImageNet competition, and his student Alex Krizhevsky. It was also after that year that more and deeper neural networks were proposed, such as the excellent vgg, GoogleLeNet. Its official data model has an accuracy rate of 57.1% and top 1-5 reaches 80.2%. This is already quite outstanding for traditional machine learning classification algorithms.\n","\n","\n","![title](https://raw.githubusercontent.com/entbappy/Branching-tutorial/19087e9920ff7db29e4103cc660bb41eca510b57/alexnet/alexnet.png)\n","\n","\n","![title](https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/alexnet/alexnet2.png)\n","\n",">The following table below explains the network structure of AlexNet:\n","\n","\n","\n","<table>\n","<thead>\n","\t<tr>\n","\t\t<th>Size / Operation</th>\n","\t\t<th>Filter</th>\n","\t\t<th>Depth</th>\n","\t\t<th>Stride</th>\n","\t\t<th>Padding</th>\n","\t\t<th>Number of Parameters</th>\n","\t\t<th>Forward Computation</th>\n","\t</tr>\n","</thead>\n","<tbody>\n","\t<tr>\n","\t\t<td>3* 227 * 227</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Conv1 + Relu</td>\n","\t\t<td>11 * 11</td>\n","\t\t<td>96</td>\n","\t\t<td>4</td>\n","\t\t<td></td>\n","\t\t<td>(11*11*3 + 1) * 96=34944</td>\n","\t\t<td>(11*11*3 + 1) * 96 * 55 * 55=105705600</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>96 * 55 * 55</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Max Pooling</td>\n","\t\t<td>3 * 3</td>\n","\t\t<td></td>\n","\t\t<td>2</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>96 * 27 * 27</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Norm</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Conv2 + Relu</td>\n","\t\t<td>5 * 5</td>\n","\t\t<td>256</td>\n","\t\t<td>1</td>\n","\t\t<td>2</td>\n","\t\t<td>(5 * 5 * 96 + 1) * 256=614656</td>\n","\t\t<td>(5 * 5 * 96 + 1) * 256 * 27 * 27=448084224</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>256 * 27 * 27</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Max Pooling</td>\n","\t\t<td>3 * 3</td>\n","\t\t<td></td>\n","\t\t<td>2</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>256 * 13 * 13</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Norm</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Conv3 + Relu</td>\n","\t\t<td>3 * 3</td>\n","\t\t<td>384</td>\n","\t\t<td>1</td>\n","\t\t<td>1</td>\n","\t\t<td>(3 * 3 * 256 + 1) * 384=885120</td>\n","\t\t<td>(3 * 3 * 256 + 1) * 384 * 13 * 13=149585280</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>384 * 13 * 13</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Conv4 + Relu</td>\n","\t\t<td>3 * 3</td>\n","\t\t<td>384</td>\n","\t\t<td>1</td>\n","\t\t<td>1</td>\n","\t\t<td>(3 * 3 * 384 + 1) * 384=1327488</td>\n","\t\t<td>(3 * 3 * 384 + 1) * 384 * 13 * 13=224345472</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>384 * 13 * 13</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Conv5 + Relu</td>\n","\t\t<td>3 * 3</td>\n","\t\t<td>256</td>\n","\t\t<td>1</td>\n","\t\t<td>1</td>\n","\t\t<td>(3 * 3 * 384 + 1) * 256=884992</td>\n","\t\t<td>(3 * 3 * 384 + 1) * 256 * 13 * 13=149563648</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>256 * 13 * 13</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Max Pooling</td>\n","\t\t<td>3 * 3</td>\n","\t\t<td></td>\n","\t\t<td>2</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>256 * 6 * 6</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Dropout (rate 0.5)</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>FC6 + Relu</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td>256 * 6 * 6 * 4096=37748736</td>\n","\t\t<td>256 * 6 * 6 * 4096=37748736</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>4096</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Dropout (rate 0.5)</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>FC7 + Relu</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td>4096 * 4096=16777216</td>\n","\t\t<td>4096 * 4096=16777216</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>4096</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>FC8 + Relu</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td>4096 * 1000=4096000</td>\n","\t\t<td>4096 * 1000=4096000</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>1000 classes</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Overall</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td>62369152=62.3 million</td>\n","\t\t<td>1135906176=1.1 billion</td>\n","\t</tr>\n","\t<tr>\n","\t\t<td>Conv VS FC</td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td></td>\n","\t\t<td>Conv:3.7million (6%) , FC: 58.6 million  (94% )</td>\n","\t\t<td>Conv: 1.08 billion (95%) , FC: 58.6 million (5%)</td>\n","\t</tr>\n","</tbody>\n","</table>\n","\n","\n","#### Why does AlexNet achieve better results?\n","\n","1. **Relu activation function is used.**\n","\n","Relu function: f (x) = max (0, x)\n","\n","![alex1](https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/alexnet/alex512.png)\n","\n","ReLU-based deep convolutional networks are trained several times faster than tanh and sigmoid- based networks. The following figure shows the number of iterations for a four-layer convolutional network based on CIFAR-10 that reached 25% training error in tanh and ReLU:\n","\n","![alex1](https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/alexnet/alex612.png)\n","\n","2. **Standardization ( Local Response Normalization )**\n","\n","After using ReLU f (x) = max (0, x), you will find that the value after the activation function has no range like the tanh and sigmoid functions, so a normalization will usually be done after ReLU, and the LRU is a steady proposal (Not sure here, it should be proposed?) One method in neuroscience is called \"Lateral inhibition\", which talks about the effect of active neurons on its surrounding neurons.\n","\n","![alex1](https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/alexnet/alex3.jpg)\n","\n","\n","3. **Dropout**\n","\n","Dropout is also a concept often said, which can effectively prevent overfitting of neural networks. Compared to the general linear model, a regular method is used to prevent the model from overfitting. In the neural network, Dropout is implemented by modifying the structure of the neural network itself. For a certain layer of neurons, randomly delete some neurons with a defined probability, while keeping the individuals of the input layer and output layer neurons unchanged, and then update the parameters according to the learning method of the neural network. In the next iteration, rerandom Remove some neurons until the end of training.\n","\n","\n","![alex1](https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/alexnet/alex4.jpg)\n","\n","\n","4. **Enhanced Data ( Data Augmentation )**\n","\n","\n","\n","**In deep learning, when the amount of data is not large enough, there are generally 4 solutions:**\n","\n",">  Data augmentation- artificially increase the size of the training set-create a batch of \"new\" data from existing data by means of translation, flipping, noise\n","\n",">  Regularization——The relatively small amount of data will cause the model to overfit, making the training error small and the test error particularly large. By adding a regular term after the Loss Function , the overfitting can be suppressed. The disadvantage is that a need is introduced Manually adjusted hyper-parameter.\n","\n",">  Dropout- also a regularization method. But different from the above, it is achieved by randomly setting the output of some neurons to zero\n","\n",">  Unsupervised Pre-training- use Auto-Encoder or RBM's convolution form to do unsupervised pre-training layer by layer, and finally add a classification layer to do supervised Fine-Tuning\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HTou3jNfuOuy"},"source":["# Code Implementation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5652,"status":"ok","timestamp":1693307619112,"user":{"displayName":"Vijay Mathe","userId":"09421281738257177814"},"user_tz":-330},"id":"wW-lXn5VKjab","outputId":"4c479ac1-95c7-449f-9b00-834e6da188f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tflearn\n","  Downloading tflearn-0.5.0.tar.gz (107 kB)\n","     ---------------------------------------- 0.0/107.3 kB ? eta -:--:--\n","     ---------------------------------------- 0.0/107.3 kB ? eta -:--:--\n","     --- ------------------------------------ 10.2/107.3 kB ? eta -:--:--\n","     --- ------------------------------------ 10.2/107.3 kB ? eta -:--:--\n","     ---------- -------------------------- 30.7/107.3 kB 220.2 kB/s eta 0:00:01\n","     -------------- ---------------------- 41.0/107.3 kB 196.9 kB/s eta 0:00:01\n","     ---------------------------- -------- 81.9/107.3 kB 353.1 kB/s eta 0:00:01\n","     ------------------------------------ 107.3/107.3 kB 366.1 kB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: numpy in c:\\users\\abhi\\appdata\\roaming\\python\\python312\\site-packages (from tflearn) (1.26.0)\n","Requirement already satisfied: six in e:\\data science 101 days chalenge\\abhi\\lib\\site-packages (from tflearn) (1.16.0)\n","Requirement already satisfied: Pillow in e:\\data science 101 days chalenge\\abhi\\lib\\site-packages (from tflearn) (10.2.0)\n","Building wheels for collected packages: tflearn\n","  Building wheel for tflearn (setup.py): started\n","  Building wheel for tflearn (setup.py): finished with status 'done'\n","  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127292 sha256=c14298b8487d0c83462bd2cca6034738f40f665c3ce2e9fdc863df5983e9d83b\n","  Stored in directory: c:\\users\\abhi\\appdata\\local\\pip\\cache\\wheels\\2e\\5f\\cd\\ffa06b65baff30574958318ce36ef9ef7af1ef3745dadaf420\n","Successfully built tflearn\n","Installing collected packages: tflearn\n","Successfully installed tflearn-0.5.0\n"]}],"source":["!pip install tflearn"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693307619113,"user":{"displayName":"Vijay Mathe","userId":"09421281738257177814"},"user_tz":-330},"id":"1Q4PPu7WuUDN"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26401,"status":"ok","timestamp":1693307645509,"user":{"displayName":"Vijay Mathe","userId":"09421281738257177814"},"user_tz":-330},"id":"BxOVzfqXIImz","outputId":"9aa6e3e7-c03d-489f-80c2-82e48dd33583"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From e:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tflearn\\__init__.py:5: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n","\n","WARNING:tensorflow:From e:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n","WARNING:tensorflow:From e:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n"]},{"ename":"ImportError","evalue":"cannot import name 'is_sequence' from 'tensorflow.python.util.nest' (e:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tensorflow\\python\\util\\nest.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get Data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtflearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moxflower17\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moxflower17\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      5\u001b[0m x, y \u001b[38;5;241m=\u001b[39m oxflower17\u001b[38;5;241m.\u001b[39mload_data()\n","File \u001b[1;32me:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tflearn\\__init__.py:25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summarize, summarize_activations, \\\n\u001b[0;32m     22\u001b[0m     summarize_gradients, summarize_variables, summarize_all\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Predefined ops\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalization\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n","File \u001b[1;32me:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tflearn\\layers\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m batch_normalization, local_response_normalization\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regression\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lstm, gru, simple_rnn, bidirectional_rnn, \\\n\u001b[0;32m     12\u001b[0m     BasicRNNCell, BasicLSTMCell, GRUCell\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m embedding\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge, merge_outputs\n","File \u001b[1;32me:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tflearn\\layers\\recurrent.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rnn_cell_impl \u001b[38;5;28;01mas\u001b[39;00m _rnn_cell, dynamic_rnn \u001b[38;5;28;01mas\u001b[39;00m _drnn\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_rnn_cell\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_sequence\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'is_sequence' from 'tensorflow.python.util.nest' (e:\\DATA SCIENCE 101 DAYS CHALENGE\\abhi\\Lib\\site-packages\\tensorflow\\python\\util\\nest.py)"]}],"source":["# Get Data\n","import tflearn.datasets.oxflower17 as oxflower17\n","from keras.utils import to_categorical\n","\n","x, y = oxflower17.load_data()\n","\n","x_train = x.astype('float32') / 255.0\n","y_train = to_categorical(y, num_classes=17)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693307645510,"user":{"displayName":"Vijay Mathe","userId":"09421281738257177814"},"user_tz":-330},"id":"bHU9oT-vvwCt","outputId":"12c67df5-4b94-438a-b166-326bee4b928c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1360, 224, 224, 3)\n","(1360, 17)\n"]}],"source":["print(x_train.shape)\n","print(y_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1693307645930,"user":{"displayName":"Vijay Mathe","userId":"09421281738257177814"},"user_tz":-330},"id":"1QCMbyu5GhcE","outputId":"25de05ee-606f-4cca-b197-4dc92cc563c6"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n","                                                                 \n"," activation (Activation)     (None, 54, 54, 96)        0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 26, 26, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n","                                                                 \n"," activation_1 (Activation)   (None, 26, 26, 256)       0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 12, 12, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 384)       885120    \n","                                                                 \n"," activation_2 (Activation)   (None, 10, 10, 384)       0         \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 10, 10, 384)      1536      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 384)         1327488   \n","                                                                 \n"," activation_3 (Activation)   (None, 8, 8, 384)         0         \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 8, 8, 384)        1536      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 6, 6, 256)         884992    \n","                                                                 \n"," activation_4 (Activation)   (None, 6, 6, 256)         0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 2, 2, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 2, 2, 256)        1024      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              4198400   \n","                                                                 \n"," activation_5 (Activation)   (None, 4096)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 4096)             16384     \n"," hNormalization)                                                 \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," activation_6 (Activation)   (None, 4096)              0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 4096)             16384     \n"," hNormalization)                                                 \n","                                                                 \n"," dense_2 (Dense)             (None, 17)                69649     \n","                                                                 \n"," activation_7 (Activation)   (None, 17)                0         \n","                                                                 \n","=================================================================\n","Total params: 24,834,833\n","Trainable params: 24,815,697\n","Non-trainable params: 19,136\n","_________________________________________________________________\n"]}],"source":["# Create a sequential model\n","model = Sequential()\n","\n","# 1st Convolutional Layer\n","model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n","model.add(Activation('relu'))\n","\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation before passing it to the next layer\n","model.add(BatchNormalization())\n","\n","# 2nd Convolutional Layer\n","model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n","model.add(Activation('relu'))\n","\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","\n","\n","# 3rd Convolutional Layer\n","model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 4th Convolutional Layer\n","model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","\n","# 5th Convolutional Layer\n","model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","\n","\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","\n","# Passing it to a dense layer\n","model.add(Flatten())\n","\n","# 1st Dense Layer\n","model.add(Dense(4096, input_shape=(224*224*3,)))\n","model.add(Activation('relu'))\n","# Add Dropout to prevent overfitting\n","model.add(Dropout(0.4))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 2nd Dense Layer\n","model.add(Dense(4096))\n","model.add(Activation('relu'))\n","# Add Dropout\n","model.add(Dropout(0.4))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# Output Layer\n","model.add(Dense(17))\n","model.add(Activation('softmax'))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1693307655416,"user":{"displayName":"Vijay Mathe","userId":"09421281738257177814"},"user_tz":-330},"id":"MMSou5UCGkQs"},"outputs":[],"source":["# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24655,"status":"ok","timestamp":1693307688831,"user":{"displayName":"Vijay Mathe","userId":"09421281738257177814"},"user_tz":-330},"id":"S8Brj24fGpM9","outputId":"4f69d112-9dcd-4adc-bdef-43dddfcea4e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 1088 samples, validate on 272 samples\n","Epoch 1/5\n","1088/1088 [==============================] - ETA: 0s - loss: 4.0937 - acc: 0.2224"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1088/1088 [==============================] - 13s 12ms/sample - loss: 4.0937 - acc: 0.2224 - val_loss: 3.0612 - val_acc: 0.0735\n","Epoch 2/5\n","1088/1088 [==============================] - 2s 2ms/sample - loss: 2.4015 - acc: 0.3851 - val_loss: 3.6139 - val_acc: 0.0588\n","Epoch 3/5\n","1088/1088 [==============================] - 2s 2ms/sample - loss: 1.7939 - acc: 0.4789 - val_loss: 5.5117 - val_acc: 0.0588\n","Epoch 4/5\n","1088/1088 [==============================] - 2s 2ms/sample - loss: 1.4491 - acc: 0.5570 - val_loss: 6.3562 - val_acc: 0.0588\n","Epoch 5/5\n","1088/1088 [==============================] - 2s 2ms/sample - loss: 1.2435 - acc: 0.6259 - val_loss: 3.7062 - val_acc: 0.0919\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7c67397eee30>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Train\n","model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHaBso7TG6YU"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
