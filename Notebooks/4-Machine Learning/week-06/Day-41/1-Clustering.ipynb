{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unsupervised Machine Learning:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "We don't have an Output that what should be predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day-41:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KMeans Clustering\n",
    "* Hierarichal Clustering\n",
    "* DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.KMeans Clustering:-\n",
    "\n",
    "```\n",
    "\n",
    "K-means is an unsupervised learning method for clustering data points. The algorithm iteratively divides data points into K clusters by minimizing the variance in each cluster.\n",
    "\n",
    "Here, we will show you how to estimate the best value for K using the elbow method, then use K-means clustering to group the data points into clusters.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](\\1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in KMeans Clustering:-\n",
    "```\n",
    "1.Initalize some K centroids.\n",
    "2.Points that are nearest to centroid just group them.\n",
    "3.Move the centroids by calculating the means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](\\3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialization of K value:-\n",
    "#### WCSS (WITH IN CLUSTER SUM OF SQUARE):----> Euclidian Distance:-\n",
    "ðŸ”´WCSS is the sum of the squared distance between each point and the centroid in a cluster\n",
    "```\n",
    "In the K-Means clustering algorithm, WCSS (Within-Cluster Sum of Squares) is a measure used to evaluate the optimal number of clusters.\n",
    "```\n",
    "![Alt text](\\2.png)\n",
    "\n",
    "## ELBOW METHODS:-\n",
    "As we know in the k-means clustering algorithm we randomly initialize k clusters and we iteratively adjust these k clusters till these k-centroids riches in an equilibrium state. However, the main thing we do before initializing these clusters is that determine how many clusters we have to use. \n",
    "![Alt text](\\2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Intialization Trap (K-Means ++) :-\n",
    "```\n",
    "This condition where a different set of clusters is generated when a different set of centroids are provided to the K-means algorithm making it inconsistent and unreliable is called the Random initialization trap.\n",
    "It algo say that we are intialized centroids at long distances.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random initialization trap can lead to inconsistency and the generation of incorrect clusters in the dataset. It can also cause the algorithm to get stuck at local optima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-means++ algorithm fixes this problem. Most tools already implement this variant. For example, R includes k-means, and the \"flexclust\" package can do k-means++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
